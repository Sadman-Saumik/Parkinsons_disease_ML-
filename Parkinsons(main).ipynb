{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parkinsons(main).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Turbo-sakib/Parkinsons_disease_ML-/blob/main/Parkinsons(main).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L44b1cO4pxUC"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj0xbaaBole-"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWSySpAZpjeb"
      },
      "source": [
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as seabornInstance \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from statistics import mean \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import lightgbm as ltb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiHkzIU8p1qc"
      },
      "source": [
        "# Performance evaluation function\n",
        "def performanceEvaluation(model, X, y, cv_, n):\n",
        "    df_temp=pd.DataFrame(columns=['Model', 'Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'nFeatures'])\n",
        "    model_name = str(model)\n",
        "    model_name = model_name.split('(')\n",
        "    model_name = model_name[0]\n",
        "    print(\"Model __: \", model_name)\n",
        "\n",
        "    accuracy = model_selection.cross_val_score(model, X, y, cv=cv_, scoring='accuracy')\n",
        "    auc = model_selection.cross_val_score(model, X, y, cv=cv_, scoring='roc_auc')\n",
        "    precision =  model_selection.cross_val_score(model, X, y, cv=cv_, scoring='precision_macro')\n",
        "    recall =  model_selection.cross_val_score(model, X, y, cv=cv_, scoring='recall_macro')\n",
        "    f1 =  model_selection.cross_val_score(model, X, y, cv=cv_, scoring='f1_macro')\n",
        "    \n",
        "    acc = accuracy.mean()\n",
        "    a = auc.mean()\n",
        "    p = precision.mean()\n",
        "    r = recall.mean()\n",
        "    f = f1.mean()\n",
        "\n",
        "    d =[ model_name, acc ,  a,  p, r,  f, n]\n",
        "    df_temp = df_temp.append(pd.Series(d,index=['Model', 'Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'nFeatures']),ignore_index=True)\n",
        "    return df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziYWFOGNqBLy"
      },
      "source": [
        "# Connecting google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzCe_Wn7qYoy"
      },
      "source": [
        "#Loading and processing the data\n",
        "\n",
        "# read the data\n",
        "dataset = pd.read_csv('drive/MyDrive/Parkinsons2008.csv')\n",
        "print(dataset.describe())\n",
        "\n",
        "df=pd.DataFrame(columns=['Model', 'Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'nFeatures'])\n",
        "\n",
        "df_chi2=pd.DataFrame(columns=['Model', 'Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'nFeatures'])\n",
        "\n",
        "df_f=pd.DataFrame(columns=['Model', 'Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'nFeatures'])\n",
        "\n",
        "df_mi=pd.DataFrame(columns=['Model', 'Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'nFeatures'])\n",
        "\n",
        "X = dataset[dataset.columns[:-1]].values\n",
        "y = dataset[dataset.columns[-1]].values\n",
        "cv = 10\n",
        "feature_n = 12\n",
        "estimator = []\n",
        "estimator.append(('ET', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=10, verbose=0,\n",
        "                     warm_start=False)))\n",
        "estimator.append(('XBG', XGBClassifier(random_state=10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEVta04qrI83"
      },
      "source": [
        "# Model Definition (Before Filters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f1VgomGrb06"
      },
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C=2.85, class_weight={}, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=10, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04vIACSJrdyD"
      },
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=-1, oob_score=False, random_state=10, verbose=0,\n",
        "                       warm_start=False)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfWKDVbErfPd"
      },
      "source": [
        "#SVM\n",
        "model = SVC(C=28.49, break_ties=False, cache_size=200, class_weight={}, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=10, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKerbYYfrg0R"
      },
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB(priors=None, var_smoothing=0.003)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxQsdKc-riZ6"
      },
      "source": [
        "#KNN\n",
        "model = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
        "                     weights='distance')\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4kypMLNrjqJ"
      },
      "source": [
        "#ExtraTree\n",
        "model = ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=10, verbose=0,\n",
        "                     warm_start=False)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir9AtPhhto_C"
      },
      "source": [
        "#Gradient Boosting\n",
        "model = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                           max_features=None, max_leaf_nodes=None,\n",
        "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                           min_samples_leaf=1, min_samples_split=2,\n",
        "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                           n_iter_no_change=None, presort='deprecated',\n",
        "                           random_state=10, subsample=1.0, tol=0.0001,\n",
        "                           validation_fraction=0.1, verbose=0,\n",
        "                           warm_start=False)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q3XiOh2tpPZ"
      },
      "source": [
        "#Light Gradient Boosting\n",
        "model = LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',\n",
        "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
        "               importance_type='split', learning_rate=0.4, max_depth=-1,\n",
        "               min_child_samples=21, min_child_weight=0.001, min_split_gain=0,\n",
        "               n_estimators=190, n_jobs=-1, num_leaves=150, objective=None,\n",
        "               random_state=10, reg_alpha=0.005, reg_lambda=0.001, silent=True,\n",
        "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYkyTnHroCzA"
      },
      "source": [
        "#CatBoost\n",
        "model = CatBoostClassifier(random_state=10)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4nBbST_-uSP"
      },
      "source": [
        "#XGBoost\n",
        "model = XGBClassifier(random_state=10)\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ylUwtT1IFm4"
      },
      "source": [
        "#Voting classifier\n",
        "model = VotingClassifier(estimators = estimator, voting ='soft')\n",
        "df = df.append(performanceEvaluation(model, X, y, cv, len(X[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XwmMlAK2lbp"
      },
      "source": [
        "# Feature selection: Filter method-chi2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6vxDiKG20IR"
      },
      "source": [
        "#normalized feature within a fange from 0 to 1\n",
        "X_norm = MinMaxScaler().fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XJoVz3ly5g5"
      },
      "source": [
        "fs = SelectKBest(chi2, k='all')\n",
        "# learn relationship from training data\n",
        "fs.fit(X_norm, y)\n",
        "# Get columns to keep and create new dataframe with those only\n",
        "cols = fs.get_support(indices=True)\n",
        "cols_name = dataset.columns[cols]\n",
        "cols_value = []\n",
        "cols_index = ['Method']\n",
        "for i in range(len(fs.scores_)):\n",
        "  cols_value.append(fs.scores_[i])\n",
        "  cols_index.append(cols_name[i])\n",
        "cols_value.insert(0,'chi2')\n",
        "df_fs_ensemble=pd.DataFrame(columns=cols_index)\n",
        "df_fs_ensemble = df_fs_ensemble.append(pd.Series(cols_value,index=cols_index),ignore_index=True)\n",
        "df_fs_ensemble"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIpjTuSY24dI"
      },
      "source": [
        "#chi2 feature selection\n",
        "X_new = SelectKBest(chi2, k=feature_n).fit_transform(X_norm,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj5jXZkB3EAx"
      },
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C=2.85, class_weight={}, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=10, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcwiMsve3G2O"
      },
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=-1, oob_score=False, random_state=10, verbose=0,\n",
        "                       warm_start=False)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjizIDjY3JZS"
      },
      "source": [
        "#SVM\n",
        "model = SVC(C=28.49, break_ties=False, cache_size=200, class_weight={}, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=10, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A9Ceh783K17"
      },
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB(priors=None, var_smoothing=0.003)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9KF18i03MXw"
      },
      "source": [
        "#KNN\n",
        "model = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
        "                     weights='distance')\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9bcg5bn3PaZ"
      },
      "source": [
        "#ExtraTree\n",
        "model = ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=10, verbose=0,\n",
        "                     warm_start=False)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAnJ59Ug3Ph-"
      },
      "source": [
        "#Gradient Boostin\n",
        "model = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                           max_features=None, max_leaf_nodes=None,\n",
        "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                           min_samples_leaf=1, min_samples_split=2,\n",
        "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                           n_iter_no_change=None, presort='deprecated',\n",
        "                           random_state=10, subsample=1.0, tol=0.0001,\n",
        "                           validation_fraction=0.1, verbose=0,\n",
        "                           warm_start=False)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmhk8JCq3Zq6"
      },
      "source": [
        "#Light Gradient Boostin\n",
        "model = LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',\n",
        "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
        "               importance_type='split', learning_rate=0.4, max_depth=-1,\n",
        "               min_child_samples=21, min_child_weight=0.001, min_split_gain=0,\n",
        "               n_estimators=190, n_jobs=-1, num_leaves=150, objective=None,\n",
        "               random_state=10, reg_alpha=0.005, reg_lambda=0.001, silent=True,\n",
        "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PQqsZQbqMZv"
      },
      "source": [
        "#CatBoost\n",
        "model = CatBoostClassifier(random_state=10)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhmDW0ZKCd9T"
      },
      "source": [
        "#XGBoost\n",
        "model = XGBClassifier(random_state=10)\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oHLmxzeX6ve"
      },
      "source": [
        "#Voting classifier\n",
        "model = VotingClassifier(estimators = estimator, voting ='soft')\n",
        "df_chi2 = df_chi2.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCxUju4f3a1D"
      },
      "source": [
        "# Feature selection: Filter method-ANOVA ftest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLulQ06z67Ti"
      },
      "source": [
        "fs = SelectKBest(f_classif, k='all')\n",
        "# learn relationship from training data\n",
        "fs.fit(X_norm, y)\n",
        "# Get columns to keep and create new dataframe with those only\n",
        "cols = fs.get_support(indices=True)\n",
        "cols_name = dataset.columns[cols]\n",
        "cols_value = []\n",
        "cols_index = ['Method']\n",
        "for i in range(len(fs.scores_)):\n",
        "  cols_value.append(fs.scores_[i])\n",
        "  cols_index.append(cols_name[i])\n",
        "cols_value.insert(0,'ANOVA_F')\n",
        "#df_fs_ensemble=pd.DataFrame(columns=cols_index)\n",
        "df_fs_ensemble = df_fs_ensemble.append(pd.Series(cols_value,index=cols_index),ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXLTj96X3o4J"
      },
      "source": [
        "#ANOVA f-test selection\n",
        "X_new = SelectKBest(f_classif, k=feature_n).fit_transform(X_norm,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZcr2bKe3zhA"
      },
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C=2.85, class_weight={}, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=10, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J2ZXb1R363e"
      },
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=-1, oob_score=False, random_state=10, verbose=0,\n",
        "                       warm_start=False)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58fhp_jn38bI"
      },
      "source": [
        "#SVM\n",
        "model = SVC(C=28.49, break_ties=False, cache_size=200, class_weight={}, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=10, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwN9YgOH3_Fz"
      },
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB(priors=None, var_smoothing=0.003)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTklvmd4A3s"
      },
      "source": [
        "#KNN\n",
        "model = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
        "                     weights='distance')\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnFMZhek4BQw"
      },
      "source": [
        "#ExtraTree\n",
        "model = ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=10, verbose=0,\n",
        "                     warm_start=False)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3d5kOrs4BYE"
      },
      "source": [
        "#Gradient Boostin\n",
        "model = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                           max_features=None, max_leaf_nodes=None,\n",
        "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                           min_samples_leaf=1, min_samples_split=2,\n",
        "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                           n_iter_no_change=None, presort='deprecated',\n",
        "                           random_state=10, subsample=1.0, tol=0.0001,\n",
        "                           validation_fraction=0.1, verbose=0,\n",
        "                           warm_start=False)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEe8rLS64BgH"
      },
      "source": [
        "#Light Gradient Boostin\n",
        "model = LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',\n",
        "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
        "               importance_type='split', learning_rate=0.4, max_depth=-1,\n",
        "               min_child_samples=21, min_child_weight=0.001, min_split_gain=0,\n",
        "               n_estimators=190, n_jobs=-1, num_leaves=150, objective=None,\n",
        "               random_state=10, reg_alpha=0.005, reg_lambda=0.001, silent=True,\n",
        "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPlaRz9AqOb4"
      },
      "source": [
        "#CatBoost\n",
        "model = CatBoostClassifier(random_state=10)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B43mNF-CgXe"
      },
      "source": [
        "#XGBoost\n",
        "model = XGBClassifier(random_state=10)\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE6ybfwgX--E"
      },
      "source": [
        "#Voting classifier\n",
        "model = VotingClassifier(estimators = estimator, voting ='soft')\n",
        "df_f = df_f.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFzkT8se3isz"
      },
      "source": [
        "# Feature selection: Filter method-Mutual Information "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNS9v_8j7Hn6"
      },
      "source": [
        "fs = SelectKBest(mutual_info_classif, k='all')\n",
        "# learn relationship from training data\n",
        "fs.fit(X_norm, y)\n",
        "# Get columns to keep and create new dataframe with those only\n",
        "cols = fs.get_support(indices=True)\n",
        "cols_name = dataset.columns[cols]\n",
        "cols_value = []\n",
        "cols_index = ['Method']\n",
        "for i in range(len(fs.scores_)):\n",
        "  cols_value.append(fs.scores_[i])\n",
        "  cols_index.append(cols_name[i])\n",
        "cols_value.insert(0,'MI')\n",
        "#df_fs_ensemble=pd.DataFrame(columns=cols_index)\n",
        "df_fs_ensemble = df_fs_ensemble.append(pd.Series(cols_value,index=cols_index),ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwFI_eqa4Dp6"
      },
      "source": [
        "# Mutual Information selection\n",
        "X_new = SelectKBest(mutual_info_classif, k=feature_n).fit_transform(X_norm,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-9pKwwd4Kih"
      },
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C=2.85, class_weight={}, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=10, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FspaYXcH4RBk"
      },
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=-1, oob_score=False, random_state=10, verbose=0,\n",
        "                       warm_start=False)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyQIef4W4SZd"
      },
      "source": [
        "#SVM\n",
        "model = SVC(C=28.49, break_ties=False, cache_size=200, class_weight={}, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=10, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F3aPB0J4T0D"
      },
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB(priors=None, var_smoothing=0.003)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D15ZXtxg4U9P"
      },
      "source": [
        "#KNN\n",
        "model = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
        "                     weights='distance')\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuWjSfx44Vkg"
      },
      "source": [
        "#ExtraTree\n",
        "model = ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=10, verbose=0,\n",
        "                     warm_start=False)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grKw8McL4Vrb"
      },
      "source": [
        "#Gradient Boostin\n",
        "model = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                           max_features=None, max_leaf_nodes=None,\n",
        "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                           min_samples_leaf=1, min_samples_split=2,\n",
        "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                           n_iter_no_change=None, presort='deprecated',\n",
        "                           random_state=10, subsample=1.0, tol=0.0001,\n",
        "                           validation_fraction=0.1, verbose=0,\n",
        "                           warm_start=False)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rBdaHis4Vyz"
      },
      "source": [
        "#Light Gradient Boostin\n",
        "model = LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt',\n",
        "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
        "               importance_type='split', learning_rate=0.4, max_depth=-1,\n",
        "               min_child_samples=21, min_child_weight=0.001, min_split_gain=0,\n",
        "               n_estimators=190, n_jobs=-1, num_leaves=150, objective=None,\n",
        "               random_state=10, reg_alpha=0.005, reg_lambda=0.001, silent=True,\n",
        "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4tIGF8-qQS1"
      },
      "source": [
        "#CatBoost\n",
        "model = CatBoostClassifier(random_state=10)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj5oVz2BCiAM"
      },
      "source": [
        "#XGBoost\n",
        "model = XGBClassifier(random_state=10)\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQDeE46eYAjw"
      },
      "source": [
        "#Voting classifier\n",
        "model = VotingClassifier(estimators = estimator, voting ='soft')\n",
        "df_mi = df_mi.append(performanceEvaluation(model, X_new, y, cv, len(X_new[0][:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXPlVmynvsk8"
      },
      "source": [
        "# Print results to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2q2WFOLVAgz"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ_z0jSvrOd"
      },
      "source": [
        "# Printing results to csv(without filters)\n",
        "df = df.sort_values(\"Accuracy\", ascending=False)\n",
        "df.to_csv('wo_selection.csv', index = None, header=True) \n",
        "files.download('wo_selection.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8D0982f4bQh"
      },
      "source": [
        "# Printing results to csv(chi2 filter)\n",
        "df_chi2 = df_chi2.sort_values(\"Accuracy\", ascending=False)\n",
        "df_chi2.to_csv('filter_chi2.csv', index = None, header=True) \n",
        "files.download('filter_chi2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeHum76v4bXl"
      },
      "source": [
        "# Printing results to csv(ANOVA f-test filter)\n",
        "df_f = df_f.sort_values(\"Accuracy\", ascending=False)\n",
        "df_f.to_csv('filter_f.csv', index = None, header=True) \n",
        "files.download('filter_f.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrSCIGXj4gyh"
      },
      "source": [
        "# Printing results to csv(Mutual Information ilter)\n",
        "df_mi = df_mi.sort_values(\"Accuracy\", ascending=False)\n",
        "df_mi.to_csv('filter_mi.csv', index = None, header=True) \n",
        "files.download('filter_mi.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "l5iFKcus_zWW",
        "outputId": "eff6fba3-2727-44d9-ab09-fc918e5a8c7f"
      },
      "source": [
        "# Printing the Filter methods score.\n",
        "df_fs_ensemble.to_csv('Enesemble_filter_score.csv', index = None, header=True) \n",
        "files.download('Enesemble_filter_score.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b8726462-570f-47ab-8e41-3a1bf82f5714\", \"Enesemble_filter_score.csv\", 1485)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}